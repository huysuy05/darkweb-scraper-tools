================================================================================
                    DARKWEB SCRAPER - COMPREHENSIVE USAGE GUIDE
================================================================================

This guide provides step-by-step instructions for setting up and using the
Darkweb Scraper tool to extract product listings and HTML from dark web
marketplaces through Tor.

================================================================================
                              TABLE OF CONTENTS
================================================================================

1. Overview
2. System Requirements
3. Installation Steps
   3.1. Install Tor
   3.2. Install Privoxy
   3.3. Install Firefox
   3.4. Install Python Dependencies
4. Configuration
   4.1. Configure Tor
   4.2. Configure Privoxy
   4.3. Verify Configuration
5. Using the Scraper
   5.1. Basic Usage
   5.2. Category-Specific Scraping
   5.3. Keyword Search Mode
   5.4. Command-Line Options
6. Output Files
7. Troubleshooting
8. Best Practices and Legal Disclaimer

================================================================================
                              1. OVERVIEW
================================================================================

The Darkweb Scraper is a Python-based tool designed to scrape product listings
from dark web marketplaces accessible via Tor (.onion domains). It features:

- Automated CAPTCHA handling (manual solving required)
- Category-specific endpoint targeting
- Product metadata extraction (title, price, listing URL)
- Full HTML archiving for each product listing
- Keyword-based page discovery
- Proxy routing through Tor SOCKS5 or HTTP (Privoxy)
- Session persistence and checkpoint recovery

================================================================================
                          2. SYSTEM REQUIREMENTS
================================================================================

Operating System:
  - macOS (tested)
  - Linux (compatible)
  - Windows (with WSL or native Tor/Privoxy)

Software Requirements:
  - Python 3.7 or higher
  - Tor (anonymity network)
  - Privoxy (HTTP proxy)
  - Firefox (web browser)
  - geckodriver (Selenium WebDriver for Firefox)

Network:
  - Internet connection
  - Ability to access Tor network (not blocked by ISP/firewall)

================================================================================
                          3. INSTALLATION STEPS
================================================================================

3.1. INSTALL TOR
----------------

macOS (using Homebrew):
  $ brew install tor

Ubuntu/Debian Linux:
  $ sudo apt update
  $ sudo apt install tor

Windows:
  Download Tor Expert Bundle from https://www.torproject.org/download/tor/
  Extract to a directory and add to PATH.

Verify installation:
  $ tor --version
  Tor version 0.x.x.x


3.2. INSTALL PRIVOXY
--------------------

macOS (using Homebrew):
  $ brew install privoxy

Ubuntu/Debian Linux:
  $ sudo apt update
  $ sudo apt install privoxy

Windows:
  Download from https://www.privoxy.org/
  Install using the Windows installer.

Verify installation:
  $ privoxy --version
  Privoxy version 3.x.x


3.3. INSTALL FIREFOX
--------------------

macOS:
  Download from https://www.mozilla.org/firefox/
  Install the .dmg file to /Applications/

Ubuntu/Debian Linux:
  $ sudo apt update
  $ sudo apt install firefox

Windows:
  Download from https://www.mozilla.org/firefox/
  Run the installer.

Verify installation:
  $ firefox --version
  Mozilla Firefox 120.x

Install geckodriver (required for Selenium):
  macOS:
    $ brew install geckodriver

  Linux:
    $ sudo apt install firefox-geckodriver
    # OR download from https://github.com/mozilla/geckodriver/releases

  Windows:
    Download from https://github.com/mozilla/geckodriver/releases
    Extract and add to PATH.


3.4. INSTALL PYTHON DEPENDENCIES
---------------------------------

1. Clone the repository:
   $ git clone https://github.com/AdilKhan000/Darkweb_Scraper.git
   $ cd Darkweb_Scraper

2. Create a virtual environment (recommended):
   $ python3 -m venv myenv
   $ source myenv/bin/activate  # On Windows: myenv\Scripts\activate

3. Install required packages:
   $ pip install -r requirements.txt

   This installs:
   - selenium (browser automation)
   - requests (HTTP client)
   - beautifulsoup4 (HTML parsing)
   - termcolor (colored terminal output)
   - PySocks (SOCKS proxy support)

================================================================================
                            4. CONFIGURATION
================================================================================

4.1. CONFIGURE TOR
------------------

Tor must be configured to listen on port 9050 for SOCKS5 connections.

1. Locate the Tor configuration file:

   macOS (Homebrew):
     /usr/local/etc/tor/torrc
     # OR
     /opt/homebrew/etc/tor/torrc

   Linux:
     /etc/tor/torrc

   Windows:
     C:\path\to\Tor\torrc

2. Edit the torrc file:
   $ sudo nano /usr/local/etc/tor/torrc  # Adjust path as needed

3. Add or uncomment these lines:

   SocksPort 9050
   ControlPort 9051

   Optional (for better anonymity):
   CookieAuthentication 1
   DataDirectory /var/lib/tor

4. Save and exit (Ctrl+O, Enter, Ctrl+X in nano).

5. Start/Restart Tor:

   macOS (Homebrew):
     $ brew services start tor
     # OR
     $ brew services restart tor

   Linux (systemd):
     $ sudo systemctl start tor
     $ sudo systemctl enable tor  # Start on boot

   Linux (non-systemd):
     $ sudo service tor start

   Windows:
     Run tor.exe from the command line or as a service.

6. Verify Tor is running:
   $ netstat -an | grep 9050
   # Should show a listening socket on 127.0.0.1:9050


4.2. CONFIGURE PRIVOXY
----------------------

Privoxy acts as an HTTP proxy that forwards traffic to Tor's SOCKS5 proxy.

1. Locate the Privoxy configuration file:

   macOS (Homebrew):
     /usr/local/etc/privoxy/config
     # OR
     /opt/homebrew/etc/privoxy/config

   Linux:
     /etc/privoxy/config

   Windows:
     C:\Program Files\Privoxy\config.txt

2. Edit the config file:
   $ sudo nano /usr/local/etc/privoxy/config  # Adjust path as needed

3. Find the line that starts with "forward-socks5" or add this line:

   forward-socks5t / 127.0.0.1:9050 .

   IMPORTANT:
   - The "t" in "forward-socks5t" enables Tor DNS resolution
   - The "." at the end is required (parent proxy)
   - Make sure there are NO other conflicting forward directives

4. Optional: Set the listen address (default is 127.0.0.1:8118):
   listen-address 127.0.0.1:8118

5. Save and exit.

6. Start/Restart Privoxy:

   macOS (Homebrew):
     $ brew services start privoxy
     # OR
     $ brew services restart privoxy

   Linux (systemd):
     $ sudo systemctl start privoxy
     $ sudo systemctl enable privoxy

   Linux (non-systemd):
     $ sudo service privoxy start

   Windows:
     Start Privoxy service from Services panel or run privoxy.exe

7. Verify Privoxy is running:
   $ netstat -an | grep 8118
   # Should show a listening socket on 127.0.0.1:8118


4.3. VERIFY CONFIGURATION
-------------------------

Test that Tor and Privoxy are working together:

1. Test SOCKS5 connection directly:
   $ curl --socks5-hostname 127.0.0.1:9050 https://check.torproject.org
   # Should return HTML indicating you're using Tor

2. Test HTTP proxy (Privoxy â†’ Tor):
   $ curl --proxy 127.0.0.1:8118 https://check.torproject.org
   # Should return HTML indicating you're using Tor

3. Check your Tor IP:
   $ curl --socks5-hostname 127.0.0.1:9050 https://api.ipify.org
   # Should return a Tor exit node IP (not your real IP)

If tests fail, review logs:
- Tor logs: Check terminal output or /var/log/tor/
- Privoxy logs: Usually in /var/log/privoxy/ or config directory

================================================================================
                          5. USING THE SCRAPER
================================================================================

5.1. BASIC USAGE
----------------

The scraper requires manual CAPTCHA solving on first run. Basic command:

$ python scraper.py --socks --socks-port 9050 --manual

Steps:
1. The script opens Firefox through Tor
2. Waits 60 seconds for session establishment
3. Prompts: "Manual mode: please solve any CAPTCHA..."
4. Solve the CAPTCHA in the browser window
5. Press Enter in the terminal to continue
6. The scraper extracts cookies and begins crawling

Output:
- products.json: Product metadata (title, price, listing URL)
- products_html.json: Full HTML for each product listing
- scraping_checkpoint.pkl: Resume point for interrupted scrapes


5.2. CATEGORY-SPECIFIC SCRAPING
--------------------------------

To scrape only specific marketplace categories (endpoints):

$ python scraper.py --socks --socks-port 9050 --manual \
  --category-endpoints /product-category/sex-aids/ /product-category/buy-steroids/

What it does:
- Restricts crawling to ONLY the specified endpoint paths
- Discovers products on those category pages
- Fetches and saves full HTML for each product listing
- Saves discovered category URLs to pages_url.json

Example with more endpoints:
$ python scraper.py --socks --socks-port 9050 --manual \
  --category-endpoints \
    /product-category/research-chemicals/ \
    /product-category/buy-pain-meds/ \
    /product-category/cocaine/

Notes:
- Endpoints must match the exact URL paths on the target site
- Use trailing slashes if the site uses them
- The scraper will NOT follow links outside these endpoints


5.3. KEYWORD SEARCH MODE
-------------------------

Find pages containing specific keywords:

$ python scraper.py --socks --socks-port 9050 --manual \
  --search-keywords "viagra" "buy steroids"

What it does:
- Crawls the entire site looking for keywords
- Saves matching URLs to pages_url.json
- Does NOT scrape products (use regular mode after)

Use case:
1. Run keyword search to find relevant pages
2. Review pages_url.json
3. Extract endpoint paths
4. Re-run with --category-endpoints for targeted scraping


5.4. COMMAND-LINE OPTIONS
--------------------------

Required Options:
--socks
  Use Tor SOCKS5 proxy (recommended for .onion sites)

--socks-port PORT
  Tor SOCKS port (default: 9050)
  Change to 9150 if using Tor Browser Bundle

--manual
  Enable manual CAPTCHA solving mode
  Required for first run on most sites

Optional Options:
--category-endpoints ENDPOINT [ENDPOINT ...]
  Restrict scraping to specific URL paths
  Example: --category-endpoints /product-category/drugs/

--search-keywords KEYWORD [KEYWORD ...]
  Crawl site for pages containing keywords
  Saves results to pages_url.json

--page-timeout SECONDS
  Selenium page load timeout (default: 300)
  Increase for slow Tor connections

--save-pages
  Save full page HTML+metadata to scraped_pages.json
  Useful for debugging or archival

--selenium-fallback
  Start a second Selenium driver for pages requests can't fetch
  Slower but more reliable

--tor-binary PATH
  Path to custom Firefox binary (e.g., Tor Browser)
  Example: --tor-binary "/Applications/Tor Browser.app/Contents/MacOS/firefox"

--tor-profile PATH
  Path to Tor Browser profile directory
  Preserves Tor Browser settings/extensions

--disable-js
  Disable JavaScript in the browser
  May break some sites but improves anonymity

Full Example:
$ python scraper.py \
  --socks \
  --socks-port 9050 \
  --manual \
  --category-endpoints /product-category/buy-steroids/ \
  --save-pages \
  --page-timeout 600


5.5. RESUMING A SCRAPE
----------------------

If the scraper is interrupted:

1. The checkpoint file (scraping_checkpoint.pkl) saves progress
2. Simply re-run the same command
3. The scraper resumes from the last saved URL

To start fresh:
$ rm scraping_checkpoint.pkl
$ python scraper.py --socks --socks-port 9050 --manual

To clear all outputs:
$ rm products.json products_html.json pages_url.json scraped_pages.json scraping_checkpoint.pkl


5.6. DUMPING COLLECTED DATA
----------------------------

View scraped products:
$ python scraper.py --dump

This prints products.json contents to stdout (formatted JSON).

Use jq for better formatting:
$ python scraper.py --dump | jq .

Count products scraped:
$ python scraper.py --dump | jq length


Use cases:
- Offline analysis of product pages
- Re-parsing HTML with different selectors
- Legal evidence collection


pages_url.json
--------------
Stores discovered URLs (used by keyword search and endpoint modes).

Structure:
[
  "http://marketplace.onion/product-category/sex-aids/",
  "http://marketplace.onion/product-category/buy-steroids/",
  ...
]


scraped_pages.json
------------------
Created when --save-pages is used. Archives all fetched pages.

Structure:
[
  {
    "url": "http://marketplace.onion/page/1/",
    "timestamp": 1697500000,
    "html": "<html>...</html>"
  },
  ...
]


scraping_checkpoint.pkl
-----------------------
Binary pickle file storing the crawl queue. Do not edit manually.

To inspect (advanced):
$ python -c "import pickle; print(pickle.load(open('scraping_checkpoint.pkl','rb')))"




================================================================================
                            END OF USAGE GUIDE
================================================================================

Last Updated: October 2025
Version: 2.0

Thank you for using the Darkweb Scraper responsibly and ethically.

================================================================================

Command lines to check which PORT tor is listening from:
pgrep -a tor || ps aux | grep -i tor | grep -v grep

# Check listening ports (look for 9050 or 9150)
lsof -nP -iTCP -sTCP:LISTEN | grep -E '9050|9150' || netstat -an | grep LISTEN | grep -E '9050|9150'